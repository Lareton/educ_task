{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a525ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DjGle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DjGle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim.downloader as api\n",
    "import pymorphy2\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70bfe184",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = json.load(open(\"custom_dataset.json\", \"rb\"))\n",
    "test_dataset = pd.read_csv(\"C://Users//DjGle//Desktop//Gleb//aiijc//EduRu//test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "391c1bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(dataset.keys())\n",
    "classes = list(dataset.values())\n",
    "\n",
    "texts_for_w2v = texts + list(test_dataset[\"task\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5acfa9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsRu = set(stopwords.words(\"russian\"))\n",
    "punctuation = set(string.punctuation + \"—\" + \"«\" + \"»\")\n",
    "\n",
    "\n",
    "def validateWord(word):\n",
    "    if word in stopWordsRu or word in punctuation:\n",
    "        return False\n",
    "    allSymValid = False\n",
    "\n",
    "    for sym in word:\n",
    "        if not sym in punctuation:\n",
    "            allSymValid = True\n",
    "            break\n",
    "\n",
    "    return allSymValid\n",
    "\n",
    "\n",
    "def prepareText(text):\n",
    "    text.replace(\"ё\", \"е\")\n",
    "    text.replace(\"\\n\", \" \")\n",
    "\n",
    "    out = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        word = word.strip()\n",
    "        if not validateWord(word):\n",
    "            continue\n",
    "        out.append(morph.parse(word.lower())[0].normal_form)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3eaaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_for_train = [prepareText(text) for text in texts_for_w2v]\n",
    "texts_for_valid = [prepareText(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef70f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55833964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83df091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(texts_for_train, window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77fb7a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203808558, 207603500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(texts_for_train, total_examples=len(texts_for_train), epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b8bd729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5219052"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"литература\", \"поэзия\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e686ddc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830ba20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ebe1dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_words = {category: model.wv.most_similar(category, topn=10)\n",
    "                      for category in [\"литература\", \"музыка\", \"спорт\", \"животное\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "19d9088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_word_distance(word, theme):\n",
    "    distance = model.distances(word, most_similar_words[theme])\n",
    "    distance.sort()\n",
    "    return distance[:min(len(distance), 3)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a96719c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_sentence_similar(sentence, theme):\n",
    "    return np.array([mean_word_similar(word, theme) for word in sentence]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "dc1a6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    predicts_dict = {k: mean_sentence_similar(sentence, k) for k in most_similar_words.keys()}\n",
    "    predicts_dict = {v: k for k, v in predicts_dict.items()}\n",
    "    predict = predicts_dict[min(list(predicts_dict))]\n",
    "    if predict == \"животное\":\n",
    "        predict = \"животные\"\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e80720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fcc385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=1500, min_df=1, stop_words=stopwords.words('russian'))\n",
    "X = vectorizer.fit_transform([\" \".join(text) for text in texts_for_valid]).toarray()\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X = tfidf.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "257dafea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "930b3e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab3aaf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b3c0689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7339791356184798"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f13e167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40635fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2308b234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44d70cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv(\"sample_submission.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "22844c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "for i, text in enumerate(list(test_df[\"task\"])):\n",
    "    text = prepareText(text)\n",
    "    predicts.append(predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "16e7de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub[\"category\"] = predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "edc3519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub.to_csv(\"sub2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27ae2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
